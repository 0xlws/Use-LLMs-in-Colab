{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#dd0000\">Notice</font>\n",
        "\n",
        "1. You must use **GPU**.\n",
        "2. You are a **Google Colab Pro** user.\n",
        "\n",
        "Otherwise you will not be able to use colab!!!"
      ],
      "metadata": {
        "id": "wJNQu3Tj9mla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone repo"
      ],
      "metadata": {
        "id": "W87F1-Di8M9R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WFuEa_H_R14",
        "outputId": "63d01728-cdae-4e7d-b0fd-86997c820eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MiniGPT-4'...\n",
            "remote: Enumerating objects: 241, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 241 (delta 66), reused 50 (delta 37), pack-reused 143\u001b[K\n",
            "Receiving objects: 100% (241/241), 57.52 MiB | 36.74 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Vision-CAIR/MiniGPT-4.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check gpu"
      ],
      "metadata": {
        "id": "QQzLoKL38P0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQiobft0yXpg",
        "outputId": "ee0fde94-a27e-4ed6-af1e-007185e81c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 20 17:50:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install package"
      ],
      "metadata": {
        "id": "gSy1wyO38TTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "7p3vtgW1_f5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MiniGPT-4/"
      ],
      "metadata": {
        "id": "XPWawh6y_jZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "BzZIcNue_pYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q salesforce-lavis\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q accelerate\n",
        "!pip install -q gradio==3.27.0"
      ],
      "metadata": {
        "id": "VyRZwh6X1gYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q h5py\n",
        "!pip install -q typing-extensions\n",
        "!pip install -q wheel\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git -U"
      ],
      "metadata": {
        "id": "3QaQcHjT2l6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pretrained_minigpt4"
      ],
      "metadata": {
        "id": "iftS7jdt8XDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/wangrongsheng/MiniGPT4/blob/main/pretrained_minigpt4.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69XCMTuCAVfO",
        "outputId": "069e2154-1c9d-4e29-ae22-f0d94d267c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-20 17:51:47--  https://huggingface.co/wangrongsheng/MiniGPT4/blob/main/pretrained_minigpt4.pth\n",
            "Resolving huggingface.co (huggingface.co)... 18.67.0.55, 18.67.0.67, 18.67.0.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.67.0.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42713 (42K) [text/html]\n",
            "Saving to: ‘pretrained_minigpt4.pth’\n",
            "\n",
            "\rpretrained_minigpt4   0%[                    ]       0  --.-KB/s               \rpretrained_minigpt4 100%[===================>]  41.71K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-20 17:51:47 (2.04 MB/s) - ‘pretrained_minigpt4.pth’ saved [42713/42713]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#660000\">Notice</font>\n",
        "\n",
        "- Set `llama_model: \"wangrongsheng/MiniGPT-4-LLaMA\"` in `minigpt4/configs/models/minigpt4.yaml`\n",
        "- Set `ckpt: 'pretrained_minigpt4.pth'` in `eval_configs/minigpt4_eval.yaml`\n",
        "\n",
        "> `wangrongsheng/MiniGPT-4-LLaMA` was created from `vicuna-13b-delta-v0` and `llama-13b-hf`"
      ],
      "metadata": {
        "id": "RqLKLejaDEUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run MiniGPT-4"
      ],
      "metadata": {
        "id": "lndJLTq89crE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo.py --cfg-path eval_configs/minigpt4_eval.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoPqDP4WC_km",
        "outputId": "6687c361-1ee0-4e54-fe80-e1e4da8f1240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
            "2023-04-20 18:11:18.964696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing Chat\n",
            "Loading VIT\n",
            "Loading VIT Done\n",
            "Loading Q-Former\n",
            "Loading Q-Former Done\n",
            "Loading LLAMA\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "Loading checkpoint shards:   0% 0/3 [00:00<?, ?it/s]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YZwzYXFPEmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}